{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd567435",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# notebooks/01_scrape_and_explore.ipynb\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs('../data/raw', exist_ok=True)\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "# 1. DOWNLOAD PRICE DATA\n",
    "print(\"Downloading HSI price data...\")\n",
    "hsi_ticker = \"^HSI\"\n",
    "start_date = \"2015-01-01\"\n",
    "end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "df_prices = yf.download(hsi_ticker, start=start_date, end=end_date)\n",
    "df_prices.reset_index(inplace=True)\n",
    "\n",
    "# Save raw price data\n",
    "df_prices.to_csv('../data/raw/hsi_price_history.csv', index=False)\n",
    "print(f\"Saved {len(df_prices)} days of price data to data/raw/hsi_price_history.csv\")\n",
    "\n",
    "# 2. GENERATE DUMMY NEWS DATA (Placeholder for real scraper)\n",
    "# In a real scenario, you would scrape news sites here.\n",
    "# For now, we generate random headlines to test the pipeline.\n",
    "print(\"\\nGenerating dummy news data for testing...\")\n",
    "\n",
    "dates = pd.date_range(start=start_date, end=end_date)\n",
    "headlines = [\n",
    "    \"HSI surges as tech stocks rally\",\n",
    "    \"Market uncertainty grows amid global tensions\",\n",
    "    \"Banking sector shows strong resilience\",\n",
    "    \"Tech giants face new regulations\",\n",
    "    \"Investors cautious ahead of Fed meeting\",\n",
    "    \"Hong Kong market rebounds strongly\",\n",
    "    \"Economic data disappoints, index falls\",\n",
    "    \"Strong earnings reports boost confidence\"\n",
    "]\n",
    "\n",
    "news_data = []\n",
    "for date in dates:\n",
    "    # Randomly assign 0-3 headlines per day\n",
    "    n_headlines = np.random.randint(0, 3)\n",
    "    for _ in range(n_headlines):\n",
    "        news_data.append({\n",
    "            'Date': date,\n",
    "            'Headline': np.random.choice(headlines)\n",
    "        })\n",
    "\n",
    "df_news = pd.DataFrame(news_data)\n",
    "df_news.to_csv('../data/raw/scraped_news_dump.csv', index=False)\n",
    "print(f\"Saved {len(df_news)} news headlines to data/raw/scraped_news_dump.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
